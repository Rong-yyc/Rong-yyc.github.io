# 模型文件格式

- [ ] pkl
- [ ] pickle
- [ ] dill
- [ ] pth
- [ ] pb
- [ ] model
- [ ] joblib
- [ ] npy
- [ ] npz

## h5/hdf5

​		`h5/hdf5` 文件是层次数据格式`（Hierarchical Data Format，HDF）`第 5 代的版本，是一种设计用于存储和组织大量数据的文件格式。h5 是一种**开源**文件格式，支持大型、复杂的异构数据，使用类似”文件目录“的结构，允许以多种不同的结构化方式组织文件中的数据，就像处理计算机上的文件一样。同时，h5 还允许嵌入元数据，使其具有自描述性。h5 文件对于存储大量数据而言拥有极大的优势。

### 特点

- **层次化结构**：具有类似文件系统的层次结构，由组（Group）和数据集（Dataset）组成。组可以包含数据集和其他组，就像文件夹可以包含文件和子文件夹一样，这种结构非常适合组织复杂的数据集。例如，在一个生物学实验的数据文件中，可以有一个名为 “实验 1” 的组，在这个组下又可以有 “样本 1”“样本 2” 等子组，每个子组下存储对应的实验数据。
- **自描述性**：文件内部包含元数据（Metadata），这些元数据描述了数据的含义、结构、来源等信息。用户可以在不依赖外部文档的情况下理解文件中的数据。例如，数据集可以有属性来描述其单位、测量时间等信息。
- **数据类型丰富**：支持多种数据类型，包括整数、浮点数、字符串、布尔值等，还可以自定义复合数据类型。这使得它能够存储各种不同类型的数据，如传感器数据、图像数据、文本数据等。
- **高效的 I/O 性能**：HDF5 针对大规模数据的读写进行了优化，支持并行 I/O 操作，可以充分利用多核处理器和分布式存储系统的性能。在处理大数据集时，能够显著提高数据的读写速度。
- **跨平台和跨语言支持**：可以在不同的操作系统（如 Windows、Linux、macOS）上使用，并且有多种编程语言的接口，如 Python（`h5py` 库）、MATLAB、Java 等，方便不同技术栈的用户使用。

### 用途

- **科学研究**：在天文学、物理学、生物学等科学领域，`.h5` 文件常用于存储实验数据、模拟结果等。例如，天文学中可以存储星系的观测数据，生物学中可以存储基因测序数据。
- **机器学习**：在深度学习中，`.h5` 文件经常用于保存模型的权重和结构。例如，Keras 框架默认使用 `.h5` 文件来保存训练好的模型，方便后续的模型部署和再训练。
- **工程领域**：在机械工程、电子工程等领域，`.h5` 文件可以用于存储工程设计数据、测试数据等。例如，汽车制造商可以使用 `.h5` 文件来存储汽车零部件的测试数据。
- **数据归档**：由于其自描述性和高效的存储方式，`.h5` 文件适合用于长期的数据归档。科研机构和企业可以将重要的数据以 `.h5` 文件的形式保存，以便后续的分析和研究。

## .json

​		`.json` 文件是采用 JSON（JavaScript Object Notation）格式的文件，用于存储和交换数据。JSON 是一种轻量级的数据交换格式，易于人类阅读和编写，同时也易于机器解析和生成。

### 特点

- **语言无关**：JSON 可以被几乎所有编程语言所解析，使其成为跨平台数据交换的理想选择。
- **结构简单**：由键值对（在对象中）和有序值列表（在数组中）构成，非常适合表示层次化的数据结构。
- **文本格式**：以纯文本形式保存，便于在网络上传输，并且容易进行版本控制。
- **标准化**：有明确的标准定义，确保了不同系统之间的互操作性。

### 用途

- **模型超参数保存**：在机器学习领域，`.json` 文件经常用来保存模型的超参数设置，以便于模型的复现和调参。

## .bin

​		`.bin` 文件是一种通用的二进制文件格式，用于存储各种类型的数据。在机器学习和深度学习领域，`.bin` 文件通常用来保存模型权重、预处理数据或其他与模型相关的二进制数据。由于其灵活性，不同的框架或工具可能会以不同方式使用 `.bin` 文件，因此具体的结构和内容取决于生成它的应用程序。

### 特点

- **紧凑**：二进制格式能够高效地存储数据，相比文本格式占用更少的磁盘空间。
- **快速读写**：直接以二进制形式读取和写入数据可以加快加载速度，适合频繁访问的应用场景。
- **非人类可读**：因为是二进制格式，所以不像JSON或XML那样可以直接用文本编辑器查看和编辑。
- **依赖于解析器**：需要特定的解析逻辑来正确读取和解释文件中的信息，这通常意味着使用者必须知道文件的确切结构或者使用生成该文件的相同工具。

### 用途

- **模型权重保存**：许多深度学习框架允许用户将训练好的模型权重保存为 `.bin` 文件，以便后续加载进行推理或继续训练。
- **预处理数据存储**：可以用来保存经过预处理的数据集，如图像特征向量等，以加速模型训练过程。
- **中间结果缓存**：在长时间运行的任务中，可以将中间计算结果保存为 `.bin` 文件，以便后续分析或调试。
- **自定义格式**：开发者可以根据自己的需求设计特定的二进制格式，并将其保存为 `.bin` 文件，用于特定应用。

## .ckpt

​		`.ckpt` 文件是 TensorFlow 和其他一些深度学习框架中用于保存模型检查点[^1]（checkpoint）的文件格式。检查点文件通常包含模型权重、优化器状态以及其他训练过程中需要保存的信息，以便在后续继续训练或评估时恢复到之前的训练状态。

### 特点

- **完整状态保存**：除了模型参数外，还可以保存优化器的状态和其他训练相关的元数据，如当前的学习率、迭代次数等。
- **断点续训**：当训练过程被中断时，可以通过加载 `.ckpt` 文件来恢复训练，避免从头开始重新训练。
- **多文件存储**：一个完整的检查点可能由多个文件组成，包括索引文件、数据文件和元图文件，其中包含了计算图即模型架构的定义。
- **灵活性**：可以指定要保存的变量，允许用户根据需求选择性地保存某些部分的状态。

### 用途

- **保存训练进度**：定期保存训练中的模型状态作为检查点，可以在意外终止后恢复训练。
- **模型共享与迁移**：通过分享 `.ckpt` 文件，可以让其他人加载你的模型并在此基础上进行研究或开发。
- **评估不同阶段的模型表现**：通过保存不同训练阶段的检查点，可以比较模型在各个阶段的表现，帮助选择最优模型。

## .pth / .pt

​		`.pth` 文件是 PyTorch 框架中用于保存模型权重（parameters）和状态的文件格式。它实际上是一个Python pickle 序列化后的文件，主要用于存储训练好的神经网络模型的参数以及其他相关信息，还可以保存优化器的状态，这对继续训练非常有用。

​		`.pt` 文件也是 PyTorch 框架中用于保存模型、张量（tensor）、优化器状态等的文件格式。其和 `.pth` 文件格式的差异主要在于，`.pth` 文件更多的侧重于保存模型的参数，而理论上来说，`.pt` 文件可以保存整个模型的状态，不过这也不是绝对的。

### 特点

- 轻量级和高效：能够快速加载到内存中，适合频繁读取和写入操作
- 与 `PyTorch` 紧密相关，通常需要在相同的 `PyTorch` 版本环境中加载，以确保兼容性

### 用途

- 保存和加载预训练模型，以便后续使用或分享给他人
- 迁移学习，使用预训练的权重作为初始值，在特定的任务上进行微调，显著减少训练时间和资源消耗
- 继续训练，如果训练被打断，可以通过加载之前保存的 `.pth` 文件来恢复训练状态，而不需要重头开始

## .safetensors

​		`.safetensors` 文件是为了解决传统 `.pt` 或 `.pth` 文件在加载时可能遇到的安全性和兼容性问题而设计的一种新的文件格式。它主要用于保存深度学习模型的权重，尤其受到 Hugging Face 社区和许多使用 PyTorch 的开发者欢迎。与传统的序列化方法不同，`.safetensors` 格式确保了更安全、更高效的模型参数存储。

### 特点

- **安全性**：避免了Python pickle机制带来的潜在安全风险，因为 `.safetensors` 不执行任何代码，只处理张量数据。
- **高效性**：提供了更快的读写速度，并且占用更少的磁盘空间，因为它直接保存二进制形式的张量数据。
- **跨框架兼容**：虽然最初是为了改进PyTorch模型的保存方式，但该格式可以被其他支持的框架读取，增加了灵活性。
- **简化依赖**：保存和加载需要 safetensors 库，即可支持 `.safetensors` 格式的解析

### 用途

- **模型权重保存与共享**：特别适合用于保存和分发预训练模型的权重，确保接收方可以在没有原始训练代码的情况下安全地加载和使用这些权重。
- **提高加载性能**：对于需要频繁加载模型的应用程序（如推理服务），采用 `.safetensors` 可以显著提升启动速度。
- **减少安全隐患**：在不确定来源的模型中，使用 `.safetensors` 可以防止恶意代码通过模型加载过程执行，增加了系统的安全性。
- **促进社区合作**：由于其开放性和易用性，`.safetensors` 已经成为Hugging Face等平台上的标准格式之一，促进了社区成员之间的模型分享和协作。

## .ggml

​		`.ggml` 是一种专门针对机器学习，尤其是大语言模型（LLMs）设计的文件格式，由 ggerganov 开发，旨在实现低资源环境下大语言模型的高效运行。

### 特点

1. **量化存储**：.ggml 文件采用量化技术存储模型权重，即将高精度的浮点数（如 32 位浮点数）转换为低精度的数据类型（如 16 位或 8 位整数）。这种方式显著减少了模型文件的大小，同时降低了内存需求，使得在内存有限的设备（如移动设备、嵌入式设备）上也能运行大语言模型。
2. **跨平台兼容性**：该格式支持多种操作系统，同时兼容不同的硬件架构，这使得开发者能够在不同的计算环境中方便地部署和运行基于.ggml 格式的模型，无需针对每种平台进行复杂的适配工作。
3. **高效推理**：.ggml 格式针对推理过程进行了优化，通过特定的数据结构和算法设计，能够在有限的计算资源下实现快速的推理速度。

### 用途

1. **本地部署**：由于对硬件资源要求较低且具备跨平台特性，非常适合在本地设备上进行机器学习模型的部署。
2. **实验与开发**：其轻量化的特点使得在资源有限的实验环境中也能方便地进行模型的调试和优化。
3. **边缘计算**：在边缘计算场景中，设备的计算资源和网络连接往往受到限制。.ggml 格式的模型能够在边缘设备上高效运行，实现实时的数据处理和决策。

## .gguf

​		`.gguf` 是一种针对大语言模型（LLMs）的量化格式文件，是 GGML 文件格式的继任者 。旨在为运行 LLMs 提供更高效、更灵活的解决方案，尤其是在消费级硬件（如带有英伟达 GPU、AMD GPU 或英特尔集成显卡的设备）上。它通过允许加载不同量化级别的模型，显著优化了内存使用，这意味着模型可以在内存有限的设备上运行。

### 特点

- **跨平台兼容性**：.gguf 文件支持多种操作系统，包括 Windows、Linux 和 macOS。这使得开发者和用户可以在不同的系统环境中使用相同格式的模型文件，方便在各种设备上部署和运行大语言模型应用。
- **支持多种架构**：该格式支持多种硬件架构，除了常见的 x86 架构，还包括 ARM 架构。这使得 .gguf 文件不仅能在传统的桌面电脑和服务器上使用，也能在基于 ARM 架构的移动设备、开发板等设备上运行，极大地拓展了大语言模型的应用场景。

### 用途

- **本地部署**：.gguf 文件让用户能够在本地设备上部署和运行大语言模型，而无需依赖云端服务。对于那些对数据隐私和安全性要求较高的用户和企业来说，本地部署可以确保数据不会离开本地环境，有效保护敏感信息。
- **研究和开发**：研究人员可以利用.gguf 文件在不同的硬件环境中快速测试和验证新的模型架构、算法和优化技术。这种灵活性有助于加速大语言模型领域的研究和创新，推动技术的不断进步。



+++

<font color="red">以下为存储整个模型的文件格式：</font>

## .onnx

​		`.onnx` 文件是采用 ONNX（Open Neural Network Exchange）格式的文件，用于表示机器学习模型，特别是深度学习模型。ONNX 是由微软、Facebook 等多家公司共同发起的一种开放式的文件格式，旨在让不同深度学习框架之间的模型转换变得更加简单。

### 特点

- **跨平台和框架**：支持多个流行的深度学习框架如 `PyTorch`、`TensorFlow`、`Keras` 等之间的模型转换，使得模型可以在不同的环境中使用。
- **标准化操作符集**：定义了一组标准的操作符（Operators），这确保了模型在不同框架间转换时的一致性。
- **优化工具链**：提供了多种优化工具来提升模型性能，例如量化、剪枝等。
- **社区支持广泛**：由于得到了众多企业和开发者的支持，拥有丰富的文档和社区资源。

### 用途

- **模型交换**：开发者可以训练一个模型然后将其导出为 `.onnx` 格式，这样其他人就可以轻松地在其他框架中加载并使用这个模型。
- **部署灵活性**：允许用户将模型从一个框架迁移到另一个更适合部署或推理的框架上，比如从研究型框架迁移到生产级框架。
- **硬件加速**：一些硬件供应商提供对 ONNX 的支持，这意味着可以直接利用特定硬件（如GPU、FPGA）上的优化库来加速模型推理过程。
- **简化工作流**：通过统一的模型表示形式，简化了从研究到生产的整个工作流，减少了重复劳动。

## .mar

​		`.mar` 文件是 Model Archive（模型归档）文件，主要用于保存完整的机器学习或深度学习模型。这种格式由 `TorchServe` 支持，`TorchServe` 是一个用于简化 PyTorch 模型服务的工具。`.mar` 文件不仅包含模型权重和架构，还可以包括其他资源如词汇表、配置文件等，所有这些都被打包到一个单独的文件中以便于分发和服务。

### 特点

- **全面性**：除了模型本身外，还可以包含额外的依赖项、配置信息、版本控制数据以及任何其他需要与模型一起部署的资源。
- **易于分发**：将模型及其所有相关资源打包成一个文件，简化了模型的分发过程，确保接收方能够获得运行模型所需的一切。
- **版本管理**：内置版本控制系统，有助于跟踪不同版本的模型，并在生产环境中实现平滑升级。
- **多框架兼容**：虽然最初为PyTorch设计，但理论上可以扩展以支持其他框架的模型，前提是这些框架提供了相应的导入导出工具。

### 用途

- **模型部署**：非常适合将训练好的模型部署到生产环境中，无论是云服务器还是边缘设备。
- **共享与协作**：研究人员和开发者可以通过分享 `.mar` 文件轻松地交换模型，促进团队内部或跨组织的合作。
- **简化推理服务搭建**：使用 TorchServe 时，可以直接加载 `.mar` 文件来快速启动一个推理服务，而无需担心模型及相关资源的独立部署问题。

## SaveModel

​		`SavedModel` 是 TensorFlow 提供的一种用于保存和加载机器学习模型的通用、恢复友好的序列化格式。它不仅包含模型的架构，还包括权重和其他训练时的状态，使得模型可以在没有原始代码的情况下被加载和使用。`SavedModel` 格式是 TensorFlow 推荐的生产环境中保存模型的方式。

### 特点

- **全面性**：保存完整的模型，包括架构、参数、优化器状态等，确保了模型可以被准确地重建。
- **跨平台兼容**：支持多种编程语言和运行环境，如 Python、C++、Java 等，方便在不同环境中部署模型。
- **版本控制**：每个 `SavedModel` 可以有多个版本，这有助于管理模型的不同迭代，并允许用户选择特定版本进行加载。
- **服务友好**：特别适合用于生产环境中的模型服务，例如通过 TensorFlow Serving 来提供高效的在线推理服务。
- **可扩展性**：可以包含自定义操作（ops）和资产（assets），如词汇表文件或其他辅助资源，这些对于某些模型可能是必需的。

### 用途

- **模型共享与发布**：由于其语言无关性，`SavedModel` 文件可以轻松地分享给其他开发者或团队成员，甚至可以通过 TensorFlow Hub 这样的平台公开发布。
- **简化部署流程**：可以直接将 `SavedModel` 部署到生产环境中，而不需要额外的转换步骤，简化了从开发到生产的过渡。
- **迁移学习与模型组合**：可以从一个 `SavedModel` 中加载部分组件（如预训练层），并在新的任务上进行微调，或者将多个模型组合成更复杂的系统。

[^1]: 模型检查点是在模型训练过程中，对模型的当前状态（包括模型参数、优化器状态等）进行定期保存的一个数据快照。简单来说，它就像是在模型训练过程中的一个个 “存档点”。