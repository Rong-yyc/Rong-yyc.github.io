# 后端优化

## 基本概念

后端优化：针对单个算子的内部具体实现优化，使得算子的性能达到最优。主要优化流程为对算子节点的输入、输出、内存循环方式和计算逻辑进行编排与转换。

与前端优化的区别在于关注点不同，前端优化具有局部或全局的视野，而后端优化只关注单个算子节点。

## 流程

后端优化的流程一般分为三步：

1. 生成低级 IR：将高级或计算图级别 IR（Graph IR）转换为低级 IR（Tensor IR）。
2. 后端优化：进行后端优化，并将 IR 转换为更低级的 IR。
3. 代码生成：根据硬件进行代码生成。

为什么不直接将 AI 编译器的后端优化委托给传统编译器来实现呢？

有两个关键原因：

1）数据形式不同：深度学习中数据形式主要为张量（Tensor）。而传统编译器不擅长对张量计算优化，更擅长对标量进行计算。

2）缺乏必要的支持：传统编译器主要针对通用编程语言，缺乏对领域特定语言 DSL 的支持，特别是对神经网络，以及相关的特殊优化。

# 算子优化

算子根据其计算形式的特点可分为访存密集型与计算密集型。

由于算子种类的多样性，并没有一个一网打尽的优化手段能解决所有算子的高性能执行方式。算子优化存在以下挑战：优化手段多样、通用性与移植性、不同优化间相互影响

## 算子优化方法

1、算子库

业界一个最为常见的方式是将预置的算子实现封装成**计算库**。算子库是指一组高度优化的计算核心函数，用于加速特定类型的计算任务，例如常见的矩阵乘法、卷积、循环神经网络等。这些算子库通常是由硬件厂商或第三方开发者编写的，旨在充分利用硬件平台的计算能力，并提供易于使用和高效的接口。

2、自动生成

目前有两种主流的自动生成算法：Auto Tuning 和 Polyhedral

# 计算与调度

- 计算：描述实现算法的具体逻辑，而不关心具体的代码实现
- 调度：对计算进行优化和控制的过程。通过调度，可以指定计算的执行顺序、内存布局、并行策略等以实现对计算性能的优化

算子调度具体执行的所有可能的调度方式称为调度空间。AI 编译器优化的目的在于通过对算子进行最佳调度，使得算子在特定硬件上的运行时间达到最优水平。

## 调度树

对于神经网络中的算子来说，其计算形式一般比较规则，是多层嵌套的循环，也很少有复杂的控制流，并且输入主要是多维张量。根据调度的要素，可以将其抽象为一个树结构，称为调度树：

- 循环节点：表示函数如何沿着给定维度进行遍历计算。循环节点与一个函数和一个变量（维度）相关联。循环节点还包含循环是按顺序运行、并行运行还是矢量化运行等信息。
- 存储节点：表示存储待使用的中间结果。
- 计算节点：调度树的叶子，表示正在执行的计算。计算节点可以有其他计算节点作为子节点，以表示内联函数而不是从中间存储加载。

## 调度变换的方式

Halide 调度变换

# 算子手工优化

## 计算分析指标

首先定义几个关键指标：

- 计算量：指当前程序经过一次完整计算发生的浮点运算个数，即时间复杂度，单位为 Flops。
- 访存量：指当前程序经过一次完整计算发生的内存交换总量，即空间复杂度。
- 模型的计算强度：计算量除以访存量就是算子的计算强度，表示计算过程中，每字节内存交换用于进行多少次浮点计算。计算强度越大，其内存使用效率越高。
- 模型的理论性能：模型在计算平台上所能达到的每秒浮点运算次数的上限，Roofline 模型给出的就是计算这个指标的方法。

## Roofline 模型

Roofline 模型是一种用于评估和分析高性能计算平台性能的有效工具。它通过分析计算量和访存量来确定在特定算力和带宽条件下，计算任务所能达到的理论性能上限。Roofline 模型的核心在于，它能够揭示硬件资源的限制，并帮助开发者和研究人员理解在现有计算平台的约束下，他们的应用程序能够实现的理论性能上限。

## 优化策略

循环优化：循环分块、循环展开、循环重排、循环融合和循环拆分

指令优化：

存储优化：内存延迟隐藏技术、双缓冲

## DSL 开发算子

Roofline 模型是一种用于评估和分析高性能计算平台性能的有效工具。它通过分析计算量和访存量来确定在特定算力和带宽条件下，计算任务所能达到的理论性能上限。Roofline 模型的核心在于，它能够揭示硬件资源的限制，并帮助开发者和研究人员理解在现有计算平台的约束下，他们的应用程序能够实现的理论性能上限。

TVM开发算子：TVM 极大的发扬了 Halide 的计算与调度思想，将可实现的优化都以调度 API 的方式呈现。相比 Triton，TVM 不局限于 CUDA，支持了更多的后端，并且也易于扩展更多后端。

Triton开发算子：Triton 是 OpenAI 研发的专为深度学习和高性能计算任务设计的编程语言和编译器，它旨在简化并优化在 GPU 上执行的复杂操作的开发。Triton 的目标是提供一个开源环境，以比 CUDA 更高的生产力编写快速代码。

# 算子循环优化

在具体硬件执行计算的时候，实际会大量地使用 for 等循环指令不断地去读取不同的数据执行重复的指令（SIMT/SIMD），因此循环优化主要是为了提升数据的局部性或者计算的并行性，从而提升整体算子性能

循环的优化方案针对不同的数据局部性和计算并行性，有不同的优化方案，如循环分块、循环展开、循环重排、循环融合、循环拆分等。

## 数据局部性

- 时间局部性：CPU 处理了一个数据以后它很有可能会对它进行第二次处理。
- 空间局部性：CPU 处理了内存中某一块的数据，它很可能会还对它附近的数据块进行读写操作。

## 循环分块

循环分块是利用 Cache 的数据局部性进行优化的一种方法。循环分块将大数据集分成多个小块以充分进行数据复用。

## 循环展开

循环展开（Loop Unrolling）将一个循环中的多次迭代展开成多个单独的迭代，以减少程序执行的开销，提高代码的运行效率。

循环展开最关键的是确定展开因子，目前主要有三种方法：启发式算法、分类器分类、迭代编译

## 循环重排

循环重排序（reorder）是矩阵乘法常见的优化方式，指的是对程序中的循环结构重新排列顺序，以优化数据访问模式。

## 循环融合

循环融合（Loop Fusion）用于将多个循环合并为一个更大的循环，将相邻或紧密间隔的循环融合在一起。

## 循环拆分

拆分主要是将循环分成多个循环，可以在有条件的循环中使用，分为无条件循环和含条件循环。通过拆分，将包含控制流的代码独立为一个循环。一部分代码只有计算，可以在加速器上计算，而加速器不支持的控制流部分就可以回退到 CPU 计算。

# 指令和存储优化

除了应用极广的循环优化，在 AI 编译器底层还存在指令和存储这两种不同优化。

## 指令优化

指令优化依赖于硬件提供的特殊加速计算指令。

1、向量化：是一种数据级并行的优化

2、张量化：

## 存储优化

存储优化关乎于如何高效地管理数据在硬件中的存储和访问。

1、访存延迟隐藏：该技术通过将内存操作与计算任务并行化，实现了两者的重叠执行，从而最大化了内存带宽和计算资源的利用效率。通过这种方式，即使在数据加载和写回阶段，也能持续执行计算任务，有效减少了因等待内存操作而产生的空闲时间。

2、存储分配

​	GPU内存管理机制：全局内存、共享内存、寄存器、常量内存和纹理内存

​	NPU内存管理机制：片上内存、内存访问模式、量化和压缩、专用内存控制器

# Auto-Tuning

在硬件平台驱动算子运行需要使用各种优化方式来提高性能，然而传统的手工编写算子库面临各种窘境，衍生出了自动生成高性能算子的的方式，称为自动调优。在编译过程中，编译器或相关工具自动调整和优化代码的执行参数，以提高程序在特定硬件上的运行效率。

自动调优的过程通常包括以下几个步骤：

1. **性能分析**：通过分析程序的运行情况，识别性能瓶颈和优化机会。
2. **参数搜索**：系统地探索不同的编译选项和运行参数，寻找最佳的配置。
3. **性能评估**：对不同的配置进行测试，评估其对性能的影响。
4. **反馈学习**：根据性能评估的结果，调整搜索策略，进一步优化参数选择。

## AutoTVM

AutoTVM 是 TVM 的第一代自动调优系统，其是基于模板的。关键组件有：

- 代码生成器
- 代价模型
- 硬件测量环境

## Ansor

作为第二代调优系统，Ansor（Auto Scheduler）取消了模板机制，优化过程可以自动、无干预的进行：无需手动指定优化方式，编译器自动应用调度原语。

Ansor 有三个关键设计，分别是程序采样器、性能微调器、任务调度器。

## Meta Scheduler

Meta Schedule 是第三代调优系统，MetaSchedule 提供以下特性：

- 用于实现手动调优、AutoTVM 风格和 AutoScheduler 风格的统一 API。
- 所有调度原语的可扩展性，包括张量化和循环分块。在自动调优中使用新的原语几乎不需要额外的努力。
- 自动化基础设施在其每个组件上都是可扩展的。每个组件的系统可以在纯 python 或 C++或两者中轻松自定义。例如，可以开发一个新的在 python 中的调度空间生成器或者新的 ProgramRunner 等。