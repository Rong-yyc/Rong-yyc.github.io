# 计算单位

市场上当一款 AI 芯片产品发布时候，经常会通过一些指标数据说明产品的能力，比如芯片制程，内存大小，核心数，带宽，算力等，这些指标体现了 AI 产品的核心竞争力。

## OPS

OPS，Operations Per Second, 每秒操作数。1 TOPS 代表处理器每秒进行一万亿次（1012）计算。

OPS/W：每瓦特运算性能。TOPS/W 评价处理器在 1W 功耗下运算能力的性能指标。

## MACs

Multiply-Accumulate Operations，乘加累计操作。1 MACs 包含一个乘法操作与一个加法操作，通常 1MACs=2FLOPs。

## FLOPs

Floating Point Operations, 浮点运算次数，用来衡量模型计算复杂度，常用作神经网络模型速度的间接衡量标准。

## MAC

Memory Access Cost，内存占用量，用来衡量模型在运行时的内存占用情况。

# AI芯片关键指标

AI 芯片设计的目标是低成本高效率的执行 AI 模型，所以衡量 AI 芯片的关键指标涉及 AI 模型软件应用层面的指标和 AI 芯片硬件市场竞争力指标两个方面

## 精度 Accuracy

理解 AI 芯片的精度指标可以从以下两个角度：

- 计算精度，比如支持计算支持的位宽，FP32/FP16 等，可以保证多少位宽内的计算结果无误差。
- 模型效果精度，AI 模型不同的任务有不同的模型效果评价标准，比如 ImageNet 图像识别任务的准确率，回归任务的均方误差等。

## 吞吐量 Throughput

吞吐量指芯片在单位时间内能处理的数据量。对于具有多核心的芯片，可以处理更多并行任务，吞吐量往往更高。

## 时延 Latency

AI 芯片的时延是指从输入数据传入芯片开始，到输出结果产生的时间间隔。

## 能耗 Energy

AI 芯片的能耗指的是在执行 AI 任务时芯片所消耗的能量。

## 系统价格 Cost

价格是市场选择 AI 产品时的重要考量指标。

**硬件自身价格：**这是指 AI 芯片本身的制造成本，包括芯片设计、制造、封装、测试等环节的费用。

**系统集成上下游全栈等成本：**除了硬件本身的成本外，还需要考虑与 AI 芯片相关的系统集成和全栈生态系统的成本。

## 易用性 Flexibility

一个好的 AI 芯片产品应该提供完善的软硬件支持、丰富的文档和教程、灵活的编程语言和框架支持，以及便捷的硬件接口和集成支持，从而满足开发者在不同应用场景下的需求，提高开发效率和用户体验。AI 芯片的易用性的具体理解为：

- **文档和教程**
- **软件支持和开发工具**
- **硬件接口和集成支持**
- **性能优化和调试工具**

# 关键设计点

AI 芯片设计的关键点围绕着如何提高吞吐量和降低时延，以及低时延和 Batch Size 之间权衡。具体的实现策略主要表现在 MACs 和 PE 两个方向。

**MACs**

减少 MACs、降低 MAC 执行时间。

**PE**

关于 PE 的优化设计方向有两个方面：**增加 PE 的核心数量**、**增加 PE 利用率**

## 评估模型在芯片上的执行情况

如果一个模型在 AI 芯片上因为芯片的内部 cache 空间有限导致性能无法提升，认为该模型属于内存受限模型（Memory Bound）；如果一个模型在 AI 芯片上因为芯片的计算单元有限导致性能无法提升，则认为该模型属于算力受限模型（Computation Bound）。

# AI芯片技术路线

作为加速应用的 AI 芯片，主要的技术路线有三种：GPU、FPGA、ASIC。

## GPU

GPU 由于其强大的并行计算能力，已经成为目前最主流的 AI 芯片加速方案。但是，GPU 作为一种通用计算芯片，在功耗和成本方面还有进一步优化的空间。此外，GPU 编程的难度也较高，对开发者的要求较高。

## FPGA

FPGA 作为一种可重构的硬件，在 AI 加速领域也有广泛的应用。与 GPU 相比，FPGA 的优势在于更低的功耗和更高的灵活性。

## ASIC

ASIC 作为专用芯片，可以针对特定的 AI 算法和应用场景进行优化，提供最高的性能和能效。如谷歌的 TPU、华为的昇腾 Ascend NPU 系列等。与 GPU 和 FPGA 相比，ASIC 可以在计算速度、功耗、成本等方面做到更加极致的优化。

但是，ASIC 的设计周期较长，前期投入大，灵活性也较差。