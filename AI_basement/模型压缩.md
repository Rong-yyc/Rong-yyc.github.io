# 模型压缩

模型压缩的目标是通过减少模型的存储空间、减少计算量或提高模型的计算效率，从而在保持模型性能的同时，降低模型部署的成本。模型压缩的目标可以概括为以下几点：

1. **减少模型显存占用**：通过压缩模型参数或使用更高效的表示方式，可以显著减少模型所需的存储空间，从而降低模型在部署和执行过程中的存储成本。
2. **加快推理速度**：通过减少模型计算过程中的乘法和加法操作，可以降低模型的计算开销，达到模型运算加速的目的。
3. **减少精度损失**：在模型压缩过程中，尽可能地减小对模型性能的影响，保持模型在任务上的精度损失最小化。这需要在压缩技术选择和参数调优过程中进行细致的权衡和实验验证，确保模型在压缩后仍能够保持较高的性能水平。

## 模型压缩四件套

我们根据如何降低权重和激活成本对模型压缩算法进行分类，有如下四大类别：

1. **模型量化（Quantization）**：通过减少模型参数的表示精度，来降低模型的存储空间和计算复杂度。
2. **参数剪枝（Pruning）**：通过删除模型中的不重要连接或参数，来减少模型的大小和计算量。
3. **知识蒸馏（Knowledge Distillation）**：指通过构建一个轻量化的小模型（学生模型），利用性能更好教师模型的信息来监督训练学生模型，以期达到更好的性能和精度。
4. **低秩分解（low-rank factorization）**：通过将模型中具体执行计算的矩阵分解为低秩的子矩阵，从而减少模型参数的数量和计算复杂度。低秩分解中，矩阵被分解为两个或多个低秩矩阵的乘积形式。

## 低比特量化

### 挑战

1. 精度挑战
2. 硬件支持程度
3. 软件算法加速思考

### 量化原理

模型量化方法可以分为以下三种：

1、量化训练（感知量化训练QAT）

2、动态离线量化（几种量化方法中性能最差的）

3、静态离线量化

### 映射方法

非饱和量化与饱和量化

线性量化与非线性量化

对称量化与非对称量化

## 模型剪枝

直接删除模型中不重要的权重

模型剪枝基于这样的假设：神经网络模型是过度参数化的，存在大量的冗余参数和连接，这些参数和连接对于模型的性能并不是必要的。

### 剪枝方法分类

1、非结构化剪枝：不考虑其结构，直接对模型中的参数或连接进行剪枝操作

2、结构化剪枝：对模型中特定的结构单元如滤波器进行剪枝操作，删除整个结构单元

### 剪枝方法

训练前剪枝、训练中剪枝、训练后剪枝、运行时剪枝

1、训练前剪枝：在网络被训练之前，基于随机初始化的权值对网络进行剪枝，主要动机是消除预训练的成本

2、训练中剪枝：在模型训练中修建神经网络，分为三种：基于稀疏正则化的方法、基于动态稀疏训练的方法、基于评分的方法

3、训练后剪枝：最流行的一种，模型预训练 → 模型剪枝 → 微调和重训练 → 评估与再剪枝

4、运行时剪枝：根据每个输入数据的具体情况来动态的修剪神经网络

## 知识蒸馏

知识蒸馏系统通常由三个部分组成：知识、蒸馏算法、师生架构

- 知识：从教师模型中提取的有价值的信息
- 蒸馏算法：用于将教师模型的知识传递给学生模型的具体方法和技术
- 师生架构：指教师模型和学生模型的设计和配置方式

### 知识类型

大型神经网路中的知识非常丰富，包括多种形式的信息，主要分为四类：

- Response-based：通常指教师模型的输出
- Feature-based：指模型中间层的输出即特征图
- Relation-based：指各网络层输出之间的关系或样本之间的关系
- Architecture-based

### 知识蒸馏模型

1、离线蒸馏：教师模型在学生模型训练之前已经完成训练，并且其参数在整个蒸馏过程中保持不变

2、在线蒸馏：教师模型和学生模型在同一训练过程中共同学习，教师模型不再是预先训练好的，而是与学生模型同步更新

3、自蒸馏：教师模型和学生模型采用相同的网络模型的在线蒸馏